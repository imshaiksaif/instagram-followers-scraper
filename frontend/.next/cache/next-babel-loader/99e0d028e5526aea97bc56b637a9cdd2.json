{"ast":null,"code":"var _s = $RefreshSig$(),\n    _jsxFileName = \"/home/imshaiksaif/Documents/social-media-scraper/frontend/components/Page.js\",\n    _s2 = $RefreshSig$();\n\nimport React from \"react\";\nvar __jsx = React.createElement;\nimport { useEffect, useState } from 'react';\nimport { ScrapeProvider } from './ScrapeContext'; // function useScrapes() {\n//   const [scrapes, setScrapes] = useState({});\n//   useEffect(() => {}\n//     (async () => {\n//       console.log('Mounting or Updating');\n//       const res = await fetch('http://localhost:4444/data');\n//       const data = await res.json();\n//       console.log(data);\n//       setScrapes(data);\n//     })(),\n//     []\n//   );\n//   return scrapes;\n// }\n\nfunction useScrapes() {\n  _s();\n\n  var _useState = useState({}),\n      scrapes = _useState[0],\n      setScrapes = _useState[1];\n\n  useEffect(function () {\n    fetch('http://localhost:4444/data').then(function (results) {\n      return results.json();\n    }).then(function (data) {\n      setScrapes(data);\n    });\n  }, []);\n  return scrapes;\n}\n\n_s(useScrapes, \"1rdW67FzIAcvzUBdClnxTTII8n0=\");\n\nexport default function Page(_ref) {\n  _s2();\n\n  var children = _ref.children;\n  var scrapes = useScrapes();\n  return __jsx(ScrapeProvider, {\n    value: {\n      scrapes: scrapes\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 33,\n      columnNumber: 5\n    }\n  }, __jsx(\"div\", {\n    className: \"page\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 38,\n      columnNumber: 7\n    }\n  }, children));\n}\n\n_s2(Page, \"y/v+XUxYOfklPgp4eNttmqxg3vE=\", false, function () {\n  return [useScrapes];\n});\n\n_c = Page;\n\nvar _c;\n\n$RefreshReg$(_c, \"Page\");","map":{"version":3,"sources":["/home/imshaiksaif/Documents/social-media-scraper/frontend/components/Page.js"],"names":["useEffect","useState","ScrapeProvider","useScrapes","scrapes","setScrapes","fetch","then","results","json","data","Page","children"],"mappings":";;;;;;AAAA,SAASA,SAAT,EAAoBC,QAApB,QAAoC,OAApC;AACA,SAASC,cAAT,QAA+B,iBAA/B,C,CAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,SAASC,UAAT,GAAsB;AAAA;;AAAA,kBACUF,QAAQ,CAAC,EAAD,CADlB;AAAA,MACbG,OADa;AAAA,MACJC,UADI;;AAGpBL,EAAAA,SAAS,CAAC,YAAM;AACdM,IAAAA,KAAK,CAAC,4BAAD,CAAL,CACGC,IADH,CACQ,UAAAC,OAAO;AAAA,aAAIA,OAAO,CAACC,IAAR,EAAJ;AAAA,KADf,EAEGF,IAFH,CAEQ,UAAAG,IAAI,EAAI;AACZL,MAAAA,UAAU,CAACK,IAAD,CAAV;AACD,KAJH;AAKD,GANQ,EAMN,EANM,CAAT;AAOA,SAAON,OAAP;AACD;;GAXQD,U;;AAYT,eAAe,SAASQ,IAAT,OAA4B;AAAA;;AAAA,MAAZC,QAAY,QAAZA,QAAY;AACzC,MAAMR,OAAO,GAAGD,UAAU,EAA1B;AACA,SACE,MAAC,cAAD;AACE,IAAA,KAAK,EAAE;AACLC,MAAAA,OAAO,EAAPA;AADK,KADT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAKE;AAAK,IAAA,SAAS,EAAC,MAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAAuBQ,QAAvB,CALF,CADF;AASD;;IAXuBD,I;UACNR,U;;;KADMQ,I","sourcesContent":["import { useEffect, useState } from 'react';\nimport { ScrapeProvider } from './ScrapeContext';\n\n// function useScrapes() {\n//   const [scrapes, setScrapes] = useState({});\n//   useEffect(() => {}\n//     (async () => {\n//       console.log('Mounting or Updating');\n//       const res = await fetch('http://localhost:4444/data');\n//       const data = await res.json();\n//       console.log(data);\n//       setScrapes(data);\n//     })(),\n//     []\n//   );\n//   return scrapes;\n// }\nfunction useScrapes() {\n  const [scrapes, setScrapes] = useState({});\n\n  useEffect(() => {\n    fetch('http://localhost:4444/data')\n      .then(results => results.json())\n      .then(data => {\n        setScrapes(data);\n      });\n  }, []);\n  return scrapes;\n}\nexport default function Page({ children }) {\n  const scrapes = useScrapes();\n  return (\n    <ScrapeProvider\n      value={{\n        scrapes,\n      }}\n    >\n      <div className=\"page\">{children}</div>\n    </ScrapeProvider>\n  );\n}\n"]},"metadata":{},"sourceType":"module"}